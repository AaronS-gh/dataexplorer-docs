---
title: log_reduce_predict_full_fl() - Azure Data Explorer
description: This article describes the log_reduce_predict_full_fl() user-defined function in Azure Data Explorer.
ms.reviewer: adieldar
ms.topic: reference
ms.date: 24/10/2022
---
# log_reduce_predict_full_fl()

The function `log_reduce_predict_full_fl()` matches lines of a semi-structured textual column to patterns. The parameters of the pattern are extracted to a separate column. The patterns are retrieved from a pre-trained model, generated by `log_reduce_train_fl()`.

The function `log_reduce_predict_fl()` parses semi structured textual columns, such as log lines, and for each line it matches the respective pattern from a pre-trained model or reports an anomaly if no matching pattern was found. The function is similar to [log_reduce_predict_fl()](log-reduce-predict-fl.md), but unlike log_reduce_predict_fl() that output a patterns summary table, this function outputs a full table containing the pattern and parameters per each line.

> [!NOTE]
> * `log_reduce_predict_full_fl()` is a [UDF (user-defined function)](../query/functions/user-defined-functions.md). For more information, see [usage](#usage).
> * This function contains inline Python and requires [enabling the python() plugin](../query/pythonplugin.md#enable-the-plugin) on the cluster.

## Syntax
`T | invoke log_reduce_predict_full_fl(`*models_tbl*`,` *model_name*`,` *reduce_col*`,` *pattern_col*`,` *parameters_col*`,` *anomaly_str*`)`

## Arguments

| Name | Type | Required | Description |
|--|--|--|--|
| *models_tbl* | table | &check; | A table  containing models generated by [log_reduce_train_fl()](log-reduce-train-fl.md). The table's schema should be (name:string, timestamp: datetime, model:string).  |
| *model_name* | string | &check; | The name of the model that will be retrieved from *models_tbl*. If the table contains few models matching the model name, the latest one will be used. |
| *reduce_col* | string | &check; | The name of the string column the function is applied to. |
| *pattern_col* | string | &check; | The name of the string column to populate the pattern. |
| *parameters_col* | string | &check; | The name of the string column to populate the pattern's parameters. |
| *anomaly_str* | string | | This string will be output for lines that have no matched pattern in the model. Default value is "ANOMALY". |

## Usage

`log_reduce_predict_full_fl()` is a user-defined [tabular function](../query/functions/user-defined-functions.md#tabular-function) to be applied using the [invoke operator](../query/invokeoperator.md). You can either embed its code in your query, or install it in your database. There are two usage options: ad hoc and persistent usage. See the below tabs for examples.

# [Ad hoc](#tab/adhoc)

For ad hoc usage, embed the code using the [let statement](../query/letstatement.md). No permission is required.

~~~kusto
let log_reduce_predict_full_fl=(tbl:(*), models_tbl: (name:string, timestamp: datetime, model:string), 
                           model_name:string, reduce_col:string, pattern_col:string, parameters_col:string, 
                           anomaly_str: string = 'ANOMALY')
{
    let model_str = toscalar(models_tbl | where name == model_name | top 1 by timestamp desc | project model);
    let kwargs = bag_pack('logs_col', reduce_col, 'output_patterns_col', pattern_col,'output_parameters_col', 
                          parameters_col, 'model', model_str, 'anomaly_str', anomaly_str, 'output_type', 'full');
    let code = ```if 1:
        from sandbox_utils import Zipackage
        Zipackage.install('LogReduceFilter.zip')
        from LogReduceFilter import LogReducePredict
        result = LogReducePredict.log_reduce_predict(df, kargs)
    ```;
    tbl
    | evaluate hint.distribution=per_node python(typeof(*), code, kwargs, external_artifacts =
    bag_pack('LogReduceFilter.zip', 'https://adiwesteurope.blob.core.windows.net/python-we/LogReduceFilter/LogReduceFilter-1.0.1.zip'))
}
;
// Predict patterns for 10 entries from the HDFS_log, based on a model that was trained on 100K entries. 
HDFS_log
| extend Patterns='', Parameters=''
| take 10
| invoke log_reduce_predict_full_fl(models_tbl=ML_models, model_name="HDFS_100k_patterns", reduce_col="data", pattern_col="Patterns", parameters_col="Parameters")
~~~

# [Persistent](#tab/persistent)

For persistent usage, use [`.create function`](../management/create-function.md). Creating a function requires [database user permission](../management/access-control/role-based-authorization.md).

### One-time installation

~~~kusto
.create-or-alter function with (folder = 'Packages\\Text', docstring = 'Apply a trained model to find common patterns in textual logs, output a full table')
log_reduce_predict_full_fl(tbl:(*), models_tbl: (name:string, timestamp: datetime, model:string), 
                           model_name:string, reduce_col:string, pattern_col:string, parameters_col:string, 
                           anomaly_str: string = 'ANOMALY')
{
    let model_str = toscalar(models_tbl | where name == model_name | top 1 by timestamp desc | project model);
    let kwargs = bag_pack('logs_col', reduce_col, 'output_patterns_col', pattern_col,'output_parameters_col', 
                          parameters_col, 'model', model_str, 'anomaly_str', anomaly_str, 'output_type', 'full');
    let code = ```if 1:
        from sandbox_utils import Zipackage
        Zipackage.install('LogReduceFilter.zip')
        from LogReduceFilter import LogReducePredict
        result = LogReducePredict.log_reduce_predict(df, kargs)
    ```;
    tbl
    | evaluate hint.distribution=per_node python(typeof(*), code, kwargs, external_artifacts =
    bag_pack('LogReduceFilter.zip', 'https://adiwesteurope.blob.core.windows.net/python-we/LogReduceFilter/LogReduceFilter-1.0.1.zip'))
}
~~~

### Usage

```kusto
// Predict patterns for 10 entries from the HDFS_log, based on a model that was trained on 100K entries. 
HDFS_log
| extend Patterns='', Parameters=''
| take 10
| invoke log_reduce_predict_full_fl(models_tbl=ML_models, model_name="HDFS_100k_patterns", reduce_col="data", pattern_col="Patterns", parameters_col="Parameters")
```

---

Result:

```kusto
data	Patterns	Parameters
081110 215858 15485 INFO dfs.DataNode$PacketResponder: Received block blk_5080254298708411681 of size 67108864 from /10.251.43.21	081110 <NUM> <NUM> INFO dfs.DataNode$PacketResponder: Received block blk_<NUM> of size <NUM> from <IP>	{"parameter_0": "215858", "parameter_1": "15485", "parameter_2": "5080254298708411681", "parameter_3": "67108864", "parameter_4": "/10.251.43.21"}
081110 215858 15494 INFO dfs.DataNode$DataXceiver: Receiving block blk_-7037346755429293022 src: /10.251.43.21:45933 dest: /10.251.43.21:50010	081110 <NUM> <NUM> INFO dfs.DataNode$DataXceiver: Receiving block blk_<NUM> src: <IP> dest: <IP>	{"parameter_0": "215858", "parameter_1": "15494", "parameter_2": "-7037346755429293022", "parameter_3": "/10.251.43.21:45933", "parameter_4": "/10.251.43.21:50010"}
081110 215858 15496 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_-7746692545918257727 terminating	081110 <NUM> <NUM> INFO dfs.DataNode$PacketResponder: PacketResponder <NUM> for block blk_<NUM> terminating	{"parameter_0": "215858", "parameter_1": "15496", "parameter_2": "2", "parameter_3": "-7746692545918257727"}
081110 215858 15496 INFO dfs.DataNode$PacketResponder: Received block blk_-7746692545918257727 of size 67108864 from /10.251.107.227	081110 <NUM> <NUM> INFO dfs.DataNode$PacketResponder: Received block blk_<NUM> of size <NUM> from <IP>	{"parameter_0": "215858", "parameter_1": "15496", "parameter_2": "-7746692545918257727", "parameter_3": "67108864", "parameter_4": "/10.251.107.227"}
081110 215858 15511 INFO dfs.DataNode$DataXceiver: Receiving block blk_-8578644687709935034 src: /10.251.107.227:39600 dest: /10.251.107.227:50010	081110 <NUM> <NUM> INFO dfs.DataNode$DataXceiver: Receiving block blk_<NUM> src: <IP> dest: <IP>	{"parameter_0": "215858", "parameter_1": "15511", "parameter_2": "-8578644687709935034", "parameter_3": "/10.251.107.227:39600", "parameter_4": "/10.251.107.227:50010"}
081110 215858 15514 INFO dfs.DataNode$DataXceiver: Receiving block blk_722881101738646364 src: /10.251.75.79:58213 dest: /10.251.75.79:50010	081110 <NUM> <NUM> INFO dfs.DataNode$DataXceiver: Receiving block blk_<NUM> src: <IP> dest: <IP>	{"parameter_0": "215858", "parameter_1": "15514", "parameter_2": "722881101738646364", "parameter_3": "/10.251.75.79:58213", "parameter_4": "/10.251.75.79:50010"}
081110 215858 15517 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_-7110736255599716271 terminating	081110 <NUM> <NUM> INFO dfs.DataNode$PacketResponder: PacketResponder <NUM> for block blk_<NUM> terminating	{"parameter_0": "215858", "parameter_1": "15517", "parameter_2": "2", "parameter_3": "-7110736255599716271"}
081110 215858 15517 INFO dfs.DataNode$PacketResponder: Received block blk_-7110736255599716271 of size 67108864 from /10.251.42.246	081110 <NUM> <NUM> INFO dfs.DataNode$PacketResponder: Received block blk_<NUM> of size <NUM> from <IP>	{"parameter_0": "215858", "parameter_1": "15517", "parameter_2": "-7110736255599716271", "parameter_3": "67108864", "parameter_4": "/10.251.42.246"}
081110 215858 15533 INFO dfs.DataNode$DataXceiver: Receiving block blk_7257432994295824826 src: /10.251.26.8:41803 dest: /10.251.26.8:50010	081110 <NUM> <NUM> INFO dfs.DataNode$DataXceiver: Receiving block blk_<NUM> src: <IP> dest: <IP>	{"parameter_0": "215858", "parameter_1": "15533", "parameter_2": "7257432994295824826", "parameter_3": "/10.251.26.8:41803", "parameter_4": "/10.251.26.8:50010"}
081110 215858 15533 INFO dfs.DataNode$DataXceiver: Receiving block blk_-7771332301119265281 src: /10.251.43.210:34258 dest: /10.251.43.210:50010	081110 <NUM> <NUM> INFO dfs.DataNode$DataXceiver: Receiving block blk_<NUM> src: <IP> dest: <IP>	{"parameter_0": "215858", "parameter_1": "15533", "parameter_2": "-7771332301119265281", "parameter_3": "/10.251.43.210:34258", "parameter_4": "/10.251.43.210:50010"}
```
